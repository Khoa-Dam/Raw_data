# Move Book Scraper

Move Book Scraper is a project that uses Scrapy to scrape content from **move-book.com** and save it as Markdown files.

## 🛠 Prerequisites

Before getting started, make sure you have the following installed:

- **Python**: Version 3.6 or higher.
- **Scrapy**: A Python framework for web scraping.
- **Operating System**: Windows, Linux, or macOS.

## 🔧 Installation

### 1. Install Python

Download and install Python from the official website: [python.org](https://www.python.org/)

Check the installed Python version:

```bash
python --version
```

### 2. Install Scrapy

Open a terminal and run:

```bash
pip install scrapy
```

Verify Scrapy installation:

```bash
scrapy --version
```

## 🚀 Clone or Create Project

### 1. Clone the repository (if using Git):

```bash
git clone <repository-url>
cd move-book-scraper
```

### 2. Or manually create a Scrapy project:

```bash
scrapy startproject markdown_scraper
cd markdown_scraper
```

Then, replace `markdown_scraper/spiders/blog_scraper.py` with the provided spider code.

## 📂 Project Structure

```
markdown_scraper/
├── markdown_scraper/
│   ├── __init__.py
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders/
│       ├── __init__.py
│       └── blog_scraper.py  # Main spider file
├── scrapy.cfg
└── output_markdown/       # Directory for Markdown output files (automatically created)
```

## ▶️ Running the Spider

Run the following command in the project directory:

```bash
cd markdown_scraper
scrapy crawl blog_scraper
```

📌 **Check Output**: Markdown files will be saved in the `output_markdown/` directory.

## 🛠 Debugging (Optional)

Run with detailed logs for debugging:

```bash
scrapy crawl blog_scraper -L DEBUG
```

## ✏️ Customization

- **Target URL**: Edit `start_urls` in `spiders/blog_scraper.py` to scrape a different starting page.
- **Output Format**: Modify the `parse_page` function in `spiders/blog_scraper.py` to change the Markdown structure.
- **Rate Limiting**: Add `DOWNLOAD_DELAY = 1` in `settings.py` to avoid overloading the server.

## ⚠️ Notes

- Ensure compliance with the **robots.txt** and the website’s terms of service.
- To prevent duplicate file names, titles are generated by appending URL segments.

## 🔍 Troubleshooting

- **Command not found**: Check your system's `PATH` variable or use the full path to execute Scrapy.
- **No data output**: Verify `start_urls` in the spider and ensure the website is accessible.

---

💡 **Move Book Scraper** helps you efficiently extract and save content from Move Book as Markdown files! 🚀
